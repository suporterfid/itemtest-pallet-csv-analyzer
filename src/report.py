# -*- coding: utf-8 -*-
from __future__ import annotations
import pandas as pd
from pathlib import Path

def write_excel(
    out_path: str,
    summary_epc: pd.DataFrame,
    unexpected: pd.DataFrame,
    ant_counts: pd.DataFrame,
    metadata: dict,
    positions_df: pd.DataFrame | None = None,
    structured_metrics: dict | None = None,
    continuous_timeline: pd.DataFrame | None = None,
    continuous_metrics: dict | None = None,
    continuous_epcs_per_minute: pd.DataFrame | pd.Series | None = None,
):
    """Persist summary artefacts to an Excel workbook.

    Parameters
    ----------
    out_path:
        Destination workbook path.
    summary_epc:
        Per-EPC aggregated statistics.
    unexpected:
        DataFrame containing the EPCs marked as unexpected.
    ant_counts:
        Aggregated antenna statistics.
    metadata:
        Dictionary with metadata parsed from the ItemTest export.
    positions_df:
        Optional pallet layout coverage table.
    structured_metrics:
        Optional dictionary with structured-mode KPIs and coverage tables.
    continuous_timeline:
        Optional timeline table generated by the continuous analysis mode.
    continuous_metrics:
        Optional dictionary with metrics and alerts for continuous mode.
    continuous_epcs_per_minute:
        Optional Series/DataFrame with aggregated counts of unique EPCs per
        minute produced by the continuous flow analysis.
    """

    out = Path(out_path)
    out.parent.mkdir(parents=True, exist_ok=True)

    metrics_info = continuous_metrics or {}
    structured_info = structured_metrics or {}
    timeline_df = None
    if continuous_timeline is not None:
        if isinstance(continuous_timeline, pd.DataFrame):
            timeline_df = continuous_timeline.copy()
        else:
            timeline_df = pd.DataFrame(continuous_timeline)
        if "entry_time" in timeline_df.columns:
            timeline_df = timeline_df.sort_values("entry_time")

    per_minute_df = None
    if continuous_epcs_per_minute is not None:
        if isinstance(continuous_epcs_per_minute, pd.Series):
            per_minute_df = (
                continuous_epcs_per_minute.sort_index()
                .rename_axis("minute")
                .reset_index()
            )
            per_minute_df.columns = ["minute", "unique_epcs"]
        else:
            per_minute_df = pd.DataFrame(continuous_epcs_per_minute)
        if not per_minute_df.empty and "minute" in per_minute_df.columns:
            per_minute_df = per_minute_df.copy()
            per_minute_df["minute"] = pd.to_datetime(
                per_minute_df["minute"], errors="coerce"
            )


    def _build_alert_lines() -> list[str]:
        alerts = [str(alert) for alert in metrics_info.get("alerts", []) if alert]
        if alerts:
            return alerts
        lines: list[str] = []
        anomalous = metrics_info.get("anomalous_epcs") or []
        if anomalous:
            sample = ", ".join(anomalous[:5])
            suffix = " ..." if len(anomalous) > 5 else ""
            lines.append(
                f"EPCs with atypical dwell time ({len(anomalous)}): {sample}{suffix}"
            )
        flag_labels = {
            "epcs_only_top_antennas": "EPCs restricted to upper antennas",
            "epcs_without_antenna": "EPCs without an identified antenna",
            "invalid_data": "Invalid data encountered",
        }
        for key, values in (metrics_info.get("inconsistency_flags") or {}).items():
            if not values:
                continue
            label = flag_labels.get(key, str(key))
            sample = ", ".join(values[:5])
            suffix = " ..." if len(values) > 5 else ""
            lines.append(f"{label} ({len(values)}): {sample}{suffix}")
        return lines

    structured_rows: list[dict[str, object]] = []
    missing_expected_df = pd.DataFrame()
    face_coverage_df = None
    row_coverage_df = None
    missing_positions_df = None
    if structured_info:
        coverage = structured_info.get("coverage_rate")
        expected_total = structured_info.get("expected_total")
        expected_found = structured_info.get("expected_found")
        if coverage is not None and not pd.isna(coverage):
            coverage_value = f"{float(coverage):.2f}%"
            if expected_total is not None and expected_found is not None:
                coverage_value += f" ({int(expected_found)}/{int(expected_total)})"
            structured_rows.append({"Metric": "Coverage rate", "Value": coverage_value})
        elif expected_total:
            structured_rows.append(
                {
                    "Metric": "Coverage rate",
                    "Value": f"0.00% (0/{int(expected_total)})",
                }
            )
        else:
            structured_rows.append({"Metric": "Coverage rate", "Value": "N/A"})

        redundancy = structured_info.get("tag_read_redundancy")
        if redundancy is not None and not pd.isna(redundancy):
            structured_rows.append(
                {
                    "Metric": "Tag read redundancy",
                    "Value": f"{float(redundancy):.2f}×",
                }
            )

        balance = structured_info.get("antenna_balance")
        if balance is not None and not pd.isna(balance):
            structured_rows.append(
                {
                    "Metric": "Antenna balance (σ)",
                    "Value": f"{float(balance):.2f}%",
                }
            )

        rssi_stability = structured_info.get("rssi_stability_index")
        if rssi_stability is not None and not pd.isna(rssi_stability):
            structured_rows.append(
                {
                    "Metric": "RSSI stability index (σ)",
                    "Value": f"{float(rssi_stability):.2f} dBm",
                }
            )

        top_performer = structured_info.get("top_performer_antenna")
        if isinstance(top_performer, dict) and top_performer.get("antenna") is not None:
            performer_label = str(top_performer.get("antenna"))
            participation = top_performer.get("participation_pct")
            if participation is not None and not pd.isna(participation):
                performer_label += f" ({float(participation):.1f}% of reads)"
            reads_value = top_performer.get("total_reads")
            if reads_value is not None and not pd.isna(reads_value):
                performer_label += f", {int(reads_value)} reads"
            structured_rows.append(
                {
                    "Metric": "Top performer antenna",
                    "Value": performer_label,
                }
            )

        missing_full = structured_info.get("missing_expected_full") or []
        missing_suffix = structured_info.get("missing_expected_suffix") or []
        missing_expected_records = [
            {"Type": "Full EPC", "Identifier": token} for token in missing_full
        ]
        missing_expected_records.extend(
            {"Type": "Suffix", "Identifier": token} for token in missing_suffix
        )
        if missing_expected_records:
            missing_expected_df = pd.DataFrame(missing_expected_records)
        structured_rows.append(
            {
                "Metric": "Missing expected tags",
                "Value": len(missing_expected_records),
            }
        )

        layout_total = structured_info.get("layout_total_positions")
        layout_read = structured_info.get("layout_read_positions")
        if layout_total is not None and layout_read is not None:
            structured_rows.append(
                {
                    "Metric": "Layout positions covered",
                    "Value": f"{int(layout_read)}/{int(layout_total)}",
                }
            )

        face_coverage_df = structured_info.get("layout_face_coverage")
        if isinstance(face_coverage_df, pd.DataFrame) and not face_coverage_df.empty:
            face_coverage_df = face_coverage_df.copy()

        row_coverage_df = structured_info.get("layout_row_coverage")
        if isinstance(row_coverage_df, pd.DataFrame) and not row_coverage_df.empty:
            row_coverage_df = row_coverage_df.copy()
        else:
            row_coverage_df = None

        missing_positions_df = structured_info.get("missing_positions_table")
        if isinstance(missing_positions_df, pd.DataFrame) and not missing_positions_df.empty:
            missing_positions_df = missing_positions_df.copy()
        else:
            missing_positions_df = None

    with pd.ExcelWriter(out, engine="xlsxwriter") as writer:
        summary_epc.to_excel(writer, index=False, sheet_name="Summary_by_EPC")
        unexpected_df = unexpected
        if unexpected_df is None:
            unexpected_df = pd.DataFrame(columns=summary_epc.columns)
        unexpected_df.to_excel(writer, index=False, sheet_name="Unexpected_EPCs")
        ant_counts.to_excel(writer, index=False, sheet_name="Reads_by_Antenna")
        if positions_df is not None:
            positions_df.to_excel(writer, index=False, sheet_name="Pallet_Positions")
        if metadata:
            md_df = pd.DataFrame(list(metadata.items()), columns=["Key", "Value"])
            md_df.to_excel(writer, index=False, sheet_name="Metadata")

        if structured_info:
            sheet_structured = "Structured_KPIs"
            structured_row = 0
            if structured_rows:
                structured_df = pd.DataFrame(structured_rows)
                structured_df.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                    startrow=structured_row,
                )
                structured_row += len(structured_df) + 2
            if not missing_expected_df.empty:
                missing_expected_df.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                    startrow=structured_row,
                )
                structured_row += len(missing_expected_df) + 2
            if isinstance(face_coverage_df, pd.DataFrame) and not face_coverage_df.empty:
                face_to_write = face_coverage_df.rename(
                    columns={
                        "total_positions": "Total positions",
                        "read_positions": "Read positions",
                        "coverage_pct": "Coverage (%)",
                        "total_reads": "Total reads",
                    }
                )
                face_to_write.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                    startrow=structured_row,
                )
                structured_row += len(face_to_write) + 2
            if isinstance(row_coverage_df, pd.DataFrame) and not row_coverage_df.empty:
                row_to_write = row_coverage_df.rename(
                    columns={
                        "total_positions": "Total positions",
                        "read_positions": "Read positions",
                        "coverage_pct": "Coverage (%)",
                        "total_reads": "Total reads",
                    }
                )
                row_to_write.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                    startrow=structured_row,
                )
                structured_row += len(row_to_write) + 2
            if isinstance(missing_positions_df, pd.DataFrame) and not missing_positions_df.empty:
                missing_positions_df.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                    startrow=structured_row,
                )
                structured_row += len(missing_positions_df) + 2
            if structured_row == 0:
                pd.DataFrame({"Message": ["No structured metrics available."]}).to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_structured,
                )

        metrics_rows: list[dict[str, object]] = []
        average_dwell = metrics_info.get("average_dwell_seconds")
        if average_dwell is not None and not pd.isna(average_dwell):
            metrics_rows.append(
                {
                    "Metric": "Average dwell time (s)",
                    "Value": round(float(average_dwell), 2),
                }
            )
        elif metrics_info:
            metrics_rows.append(
                {
                    "Metric": "Average dwell time (s)",
                    "Value": "N/A",
                }
            )
        total_events = metrics_info.get("total_events")
        if total_events is not None and not pd.isna(total_events):
            metrics_rows.append(
                {
                    "Metric": "Entry/exit events",
                    "Value": int(total_events),
                }
            )
        elif metrics_info:
            metrics_rows.append(
                {
                    "Metric": "Entry/exit events",
                    "Value": "N/A",
                }
            )
        dominant = metrics_info.get("dominant_antenna")
        if dominant is not None and str(dominant) != "" and not (
            isinstance(dominant, float) and pd.isna(dominant)
        ):
            try:
                display_dominant = int(dominant)
            except (TypeError, ValueError):
                display_dominant = dominant
            metrics_rows.append(
                {
                    "Metric": "Dominant antenna",
                    "Value": display_dominant,
                }
            )
        elif metrics_info:
            metrics_rows.append(
                {
                    "Metric": "Dominant antenna",
                    "Value": "N/A",
                }
            )
        mean_epcs = metrics_info.get("epcs_per_minute_mean")
        if mean_epcs is not None and not pd.isna(mean_epcs):
            metrics_rows.append(
                {
                    "Metric": "Average active EPCs/min",
                    "Value": round(float(mean_epcs), 2),
                }
            )
        peak_value = metrics_info.get("epcs_per_minute_peak")
        if peak_value is not None and not pd.isna(peak_value):
            peak_time = metrics_info.get("epcs_per_minute_peak_time")
            peak_label: str
            if peak_time is not None:
                try:
                    peak_ts = pd.to_datetime(peak_time)
                    if pd.isna(peak_ts):
                        raise ValueError
                    peak_label = peak_ts.strftime("%Y-%m-%d %H:%M")
                except Exception:
                    peak_label = str(peak_time)
                value_repr = f"{int(peak_value)} at {peak_label}"
            else:
                value_repr = int(peak_value)
            metrics_rows.append(
                {
                    "Metric": "Peak active EPCs/min",
                    "Value": value_repr,
                }
            )

        alerts_lines = _build_alert_lines()

        if metrics_rows or alerts_lines or timeline_df is not None or per_minute_df is not None:
            sheet_name = "Fluxo_Contínuo"
            start_row = 0
            if metrics_rows:
                metrics_df = pd.DataFrame(metrics_rows)
                metrics_df.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_name,
                    startrow=start_row,
                )
                start_row += len(metrics_rows) + 2
            if alerts_lines:
                alerts_df = pd.DataFrame({"Alerts": alerts_lines})
                alerts_df.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_name,
                    startrow=start_row,
                )
                start_row += len(alerts_lines) + 2
            elif start_row and metrics_rows:
                start_row += 1
            if per_minute_df is not None and not per_minute_df.empty:
                per_minute_to_write = per_minute_df.copy()
                if "minute" in per_minute_to_write.columns:
                    per_minute_to_write["minute"] = per_minute_to_write["minute"].dt.strftime(
                        "%Y-%m-%d %H:%M"
                    )
                per_minute_to_write.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_name,
                    startrow=start_row,
                )
                start_row += len(per_minute_to_write) + 2
            if timeline_df is not None:
                timeline_to_write = timeline_df.copy()
                timeline_to_write.to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_name,
                    startrow=start_row,
                )
            elif start_row == 0:
                pd.DataFrame(
                    {"Message": ["No continuous flow data available."]}
                ).to_excel(
                    writer,
                    index=False,
                    sheet_name=sheet_name,
                )
